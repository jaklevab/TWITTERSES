{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/data_files/UKSOC_rep/')\n",
    "from helpers_locs_to_home import time_2_date\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdmn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.ticker as tkr\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle\n",
    "import re;pat = re.compile(r'''(-*\\d+\\.\\d+ -*\\d+\\.\\d+);*''');new_geo=[]\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SVM Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Random Forest Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 500 candidates, totalling 12500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 672 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1122 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1672 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2322 tasks      | elapsed: 50.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3072 tasks      | elapsed: 66.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3922 tasks      | elapsed: 82.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4872 tasks      | elapsed: 101.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5922 tasks      | elapsed: 124.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7072 tasks      | elapsed: 148.8min\n",
      "[Parallel(n_jobs=-1)]: Done 8322 tasks      | elapsed: 174.2min\n",
      "[Parallel(n_jobs=-1)]: Done 9672 tasks      | elapsed: 199.3min\n",
      "[Parallel(n_jobs=-1)]: Done 11122 tasks      | elapsed: 229.0min\n",
      "[Parallel(n_jobs=-1)]: Done 12500 out of 12500 | elapsed: 254.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters:  {'bootstrap': True, 'criterion': 'gini', 'max_depth': 38, 'min_samples_leaf': 0.007877583208959238, 'min_samples_split': 0.0069437095447349995}\n",
      "Best model roc auc score:  0.6802543698038217\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer, StandardScaler, scale\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, n_jobs=1)\n",
    "param_distributions = {'criterion': ['gini', 'gini', 'entropy'],\n",
    "                       'max_depth': range(2,50),\n",
    "                       'min_samples_split': uniform(loc=0, scale=0.2),\n",
    "                       'min_samples_leaf': uniform(loc=0, scale=0.2),\n",
    "                       'bootstrap': [True, True, False]}\n",
    "\n",
    "\n",
    "n_splits = 5\n",
    "n_repeats = 5\n",
    "n_iter = 500\n",
    "n_jobs = -1\n",
    "verbose = 1\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "scorer = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "model = RandomizedSearchCV(clf, param_distributions, n_iter=n_iter, scoring=scorer, n_jobs=n_jobs, cv=cv, verbose=verbose)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Best model parameters: \", model.best_params_)\n",
    "print(\"Best model roc auc score: \", model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=38, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=0.007877583208959238,\n",
       "            min_samples_split=0.0069437095447349995,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.56      0.59       752\n",
      "          1       0.60      0.68      0.64       738\n",
      "\n",
      "avg / total       0.62      0.62      0.61      1490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_rf_best=RandomForestClassifier(bootstrap= True,\n",
    "                                   criterion= 'gini',\n",
    "                                   max_depth= 38,\n",
    "                                   min_samples_leaf= 0.007877583208959238,\n",
    "                                   min_samples_split=0.0069437095447349995)\n",
    "clf_rf_best.fit(X_train, y_train);\n",
    "print(classification_report(y_test,clf_rf_best.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0284a5e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probs = clf_rf_best.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer, StandardScaler, scale\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/data_files/UKSOC_rep/uksoc_xgb_data.p\",\"rb\"))\n",
    "\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reaal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer, StandardScaler, scale\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/data_files/UKSOC_rep/uksoc_xgb_data.p\",\"rb\"))\n",
    "\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "dic_res={\"best_params\":[],\"best_score\":[],\"auc\":[],\"fpr\":[],\"tpr\":[],\"threshold\":[]}\n",
    "nb_rep_test=5\n",
    "\n",
    "    \n",
    "for i in tqdm(range(1,nb_rep_test+1)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = SVC()\n",
    "    param_distributions = {'C': 10**np.random.uniform(low=-5,high=1),\n",
    "                           'gamma': 10**np.random.uniform(low=-5,high=1),\n",
    "                           'degree': range(1,4),\n",
    "                           'kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]}\n",
    "    n_splits = 5\n",
    "    n_repeats = 5\n",
    "    n_iter = 500\n",
    "    n_jobs = -1\n",
    "    verbose = 1\n",
    "    #\n",
    "    cv_xgb = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    scorer_xgb = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "    model_xgb = RandomizedSearchCV(clf_xgb, param_distributions, n_iter=n_iter,\n",
    "                                   scoring=scorer_xgb, n_jobs=n_jobs, cv=cv_xgb, verbose=verbose)\n",
    "    #\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print(\"Best model parameters: \", model_xgb.best_params_)\n",
    "    print(\"Best model roc auc score: \", model_xgb.best_score_)\n",
    "    #\n",
    "    #Mira brunch\n",
    "    clf_xgb_best=model_xgb.best_estimator_\n",
    "    clf_xgb_best.fit(X_train,y_train)\n",
    "    #\n",
    "    probs = clf_xgb_best.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    dic_res[\"best_params\"].append(model_xgb.best_params_)\n",
    "    dic_res[\"best_score\"].append(model_xgb.best_score_)\n",
    "    dic_res[\"fpr\"].append(fpr)\n",
    "    dic_res[\"tpr\"].append(tpr)\n",
    "    dic_res[\"threshold\"].append(threshold)\n",
    "    dic_res[\"auc\"].append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer, StandardScaler, scale\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/data_files/UKSOC_rep/uksoc_xgb_data.p\",\"rb\"))\n",
    "\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "dic_res={\"best_params\":[],\"best_score\":[],\"auc\":[],\"fpr\":[],\"tpr\":[],\"threshold\":[]}\n",
    "nb_rep_test=1\n",
    "\n",
    "    \n",
    "for i in tqdm(range(1,nb_rep_test+1)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = SVC(kernel=\"rbf\",probability=False)\n",
    "    param_distributions = {'C': 10**np.random.uniform(low=-5,high=1),\n",
    "                           'gamma': 10**np.random.uniform(low=-5,high=1)}\n",
    "    n_splits = 5\n",
    "    n_repeats = 5\n",
    "    n_iter = 500\n",
    "    n_jobs = -1\n",
    "    verbose = 1\n",
    "    #\n",
    "    cv_xgb = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    scorer_xgb = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "    model_xgb = RandomizedSearchCV(clf_xgb, param_distributions, n_iter=n_iter,\n",
    "                                   scoring=scorer_xgb, n_jobs=n_jobs, cv=cv_xgb, verbose=verbose)\n",
    "    #\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print(\"Best model parameters: \", model_xgb.best_params_)\n",
    "    print(\"Best model roc auc score: \", model_xgb.best_score_)\n",
    "    #\n",
    "    #Mira brunch\n",
    "    clf_xgb_best=model_xgb.best_estimator_\n",
    "    clf_xgb_best.probability=True\n",
    "    clf_xgb_best.fit(X_train,y_train)\n",
    "    #\n",
    "    probs = clf_xgb_best.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    dic_res[\"best_params\"].append(model_xgb.best_params_)\n",
    "    dic_res[\"best_score\"].append(model_xgb.best_score_)\n",
    "    dic_res[\"fpr\"].append(fpr)\n",
    "    dic_res[\"tpr\"].append(tpr)\n",
    "    dic_res[\"threshold\"].append(threshold)\n",
    "    dic_res[\"auc\"].append(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer, StandardScaler, scale\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/data_files/UKSOC_rep/uksoc_xgb_data.p\",\"rb\"))\n",
    "\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "dic_res={\"best_params\":[],\"best_score\":[],\"auc\":[],\"fpr\":[],\"tpr\":[],\"threshold\":[]}\n",
    "nb_rep_test=5\n",
    "\n",
    "    \n",
    "for i in tqdm(range(1,nb_rep_test+1)):\n",
    "    stump_clf =  DecisionTreeClassifier(random_state=i, )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = AdaBoostClassifier(base_estimator = stump_clf)\n",
    "    param_distributions = {\n",
    "              \"n_estimators\": list(range(1,500)),\n",
    "              \"learning_rate\": uniform(0.01, 1),\n",
    "    }\n",
    "    #\n",
    "    n_splits = 5\n",
    "    n_repeats = 5\n",
    "    n_iter = 500\n",
    "    n_jobs = 90\n",
    "    verbose = 1\n",
    "    #\n",
    "    cv_xgb = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    scorer_xgb = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "    model_xgb = RandomizedSearchCV(clf_xgb, param_distributions, n_iter=n_iter,\n",
    "                                   scoring=scorer_xgb, n_jobs=n_jobs, cv=cv_xgb, verbose=verbose)\n",
    "    #\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print(\"Best model parameters: \", model_xgb.best_params_)\n",
    "    print(\"Best model roc auc score: \", model_xgb.best_score_)\n",
    "    #\n",
    "    #Mira brunch\n",
    "    clf_xgb_best=model_xgb.best_estimator_\n",
    "    clf_xgb_best.fit(X_train,y_train)\n",
    "    #\n",
    "    probs = clf_xgb_best.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    dic_res[\"best_params\"].append(model_xgb.best_params_)\n",
    "    dic_res[\"best_score\"].append(model_xgb.best_score_)\n",
    "    dic_res[\"fpr\"].append(fpr)\n",
    "    dic_res[\"tpr\"].append(tpr)\n",
    "    dic_res[\"threshold\"].append(threshold)\n",
    "    dic_res[\"auc\"].append(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkedIn Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer, StandardScaler, scale\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/data_files/UKSOC_rep/linkedin/linkedin_data/xgb_data.p\",\"rb\"))\n",
    "\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "dic_res={\"best_params\":[],\"best_score\":[],\"auc\":[],\"fpr\":[],\"tpr\":[],\"threshold\":[]}\n",
    "nb_rep_test=5\n",
    "\n",
    "    \n",
    "for i in tqdm(range(1,nb_rep_test+1)):\n",
    "    stump_clf =  DecisionTreeClassifier(random_state=i, )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = AdaBoostClassifier(base_estimator = stump_clf)\n",
    "    param_distributions = {\n",
    "              \"n_estimators\": list(range(1,500)),\n",
    "              \"learning_rate\": uniform(0.01, 1),\n",
    "    }\n",
    "    #\n",
    "    n_splits = 5\n",
    "    n_repeats = 5\n",
    "    n_iter = 500\n",
    "    n_jobs = 90\n",
    "    verbose = 1\n",
    "    #\n",
    "    cv_xgb = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    scorer_xgb = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "    model_xgb = RandomizedSearchCV(clf_xgb, param_distributions, n_iter=n_iter,\n",
    "                                   scoring=scorer_xgb, n_jobs=n_jobs, cv=cv_xgb, verbose=verbose)\n",
    "    #\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print(\"Best model parameters: \", model_xgb.best_params_)\n",
    "    print(\"Best model roc auc score: \", model_xgb.best_score_)\n",
    "    #\n",
    "    #Mira brunch\n",
    "    clf_xgb_best=model_xgb.best_estimator_\n",
    "    clf_xgb_best.fit(X_train,y_train)\n",
    "    #\n",
    "    probs = clf_xgb_best.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    dic_res[\"best_params\"].append(model_xgb.best_params_)\n",
    "    dic_res[\"best_score\"].append(model_xgb.best_score_)\n",
    "    dic_res[\"fpr\"].append(fpr)\n",
    "    dic_res[\"tpr\"].append(tpr)\n",
    "    dic_res[\"threshold\"].append(threshold)\n",
    "    dic_res[\"auc\"].append(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer, StandardScaler, scale\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/icdm18/issues/archi_xgb_data.p\",\"rb\"))\n",
    "\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "dic_res={\"best_params\":[],\"best_score\":[],\"auc\":[],\"fpr\":[],\"tpr\":[],\"threshold\":[]}\n",
    "nb_rep_test=10\n",
    "\n",
    "    \n",
    "for i in tqdm(range(5,nb_rep_test+1)):\n",
    "    stump_clf =  DecisionTreeClassifier(random_state=i, )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = AdaBoostClassifier(base_estimator = stump_clf)\n",
    "    param_distributions = {\n",
    "              \"n_estimators\": list(range(1,500)),\n",
    "              \"learning_rate\": uniform(0.01, 1),\n",
    "    }\n",
    "    #\n",
    "    n_splits = 5\n",
    "    n_repeats = 5\n",
    "    n_iter = 500\n",
    "    n_jobs = -1\n",
    "    verbose = 1\n",
    "    #\n",
    "    cv_xgb = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    scorer_xgb = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "    model_xgb = RandomizedSearchCV(clf_xgb, param_distributions, n_iter=n_iter,\n",
    "                                   scoring=scorer_xgb, n_jobs=n_jobs, cv=cv_xgb, verbose=verbose)\n",
    "    #\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print(\"Best model parameters: \", model_xgb.best_params_)\n",
    "    print(\"Best model roc auc score: \", model_xgb.best_score_)\n",
    "    #\n",
    "    #Mira brunch\n",
    "    clf_xgb_best=model_xgb.best_estimator_\n",
    "    clf_xgb_best.fit(X_train,y_train)\n",
    "    #\n",
    "    probs = clf_xgb_best.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    dic_res[\"best_params\"].append(model_xgb.best_params_)\n",
    "    dic_res[\"best_score\"].append(model_xgb.best_score_)\n",
    "    dic_res[\"fpr\"].append(fpr)\n",
    "    dic_res[\"tpr\"].append(tpr)\n",
    "    dic_res[\"threshold\"].append(threshold)\n",
    "    dic_res[\"auc\"].append(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer, StandardScaler, scale\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/data_files/UKSOC_rep/uksoc_xgb_data.p\",\"rb\"))\n",
    "\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "dic_res={\"best_params\":[],\"best_score\":[],\"auc\":[],\"fpr\":[],\"tpr\":[],\"threshold\":[]}\n",
    "nb_rep_test=5\n",
    "\n",
    "for i in tqdm(range(1,nb_rep_test+1)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = RandomForestClassifier(n_estimators=1000, n_jobs=1)\n",
    "    param_distributions = {'criterion': ['gini', 'gini', 'entropy'],\n",
    "                           'max_depth': range(2,50),\n",
    "                           'min_samples_split': uniform(loc=0, scale=0.2),\n",
    "                           'min_samples_leaf': uniform(loc=0, scale=0.2),\n",
    "                           'bootstrap': [True, True, False]}\n",
    "    n_splits = 5\n",
    "    n_repeats = 5\n",
    "    n_iter = 500\n",
    "    n_jobs = -1\n",
    "    verbose = 1\n",
    "    #\n",
    "    cv_xgb = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    scorer_xgb = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "    model_xgb = RandomizedSearchCV(clf_xgb, param_distributions, n_iter=n_iter,\n",
    "                                   scoring=scorer_xgb, n_jobs=n_jobs, cv=cv_xgb, verbose=verbose)\n",
    "    #\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print(\"Best model parameters: \", model_xgb.best_params_)\n",
    "    print(\"Best model roc auc score: \", model_xgb.best_score_)\n",
    "    #\n",
    "    #Mira brunch\n",
    "    clf_xgb_best=model_xgb.best_estimator_\n",
    "    clf_xgb_best.fit(X_train,y_train)\n",
    "    #\n",
    "    probs = clf_xgb_best.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    dic_res[\"best_params\"].append(model_xgb.best_params_)\n",
    "    dic_res[\"best_score\"].append(model_xgb.best_score_)\n",
    "    dic_res[\"fpr\"].append(fpr)\n",
    "    dic_res[\"tpr\"].append(tpr)\n",
    "    dic_res[\"threshold\"].append(threshold)\n",
    "    dic_res[\"auc\"].append(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer, StandardScaler, scale\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/data_files/UKSOC_rep/linkedin/linkedin_data/xgb_data.p\",\"rb\"))\n",
    "\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "dic_res={\"best_params\":[],\"best_score\":[],\"auc\":[],\"fpr\":[],\"tpr\":[],\"threshold\":[]}\n",
    "nb_rep_test=5\n",
    "\n",
    "for i in tqdm(range(1,nb_rep_test+1)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = RandomForestClassifier(n_estimators=1000, n_jobs=1)\n",
    "    param_distributions = {'criterion': ['gini', 'gini', 'entropy'],\n",
    "                           'max_depth': range(2,50),\n",
    "                           'min_samples_split': uniform(loc=0, scale=0.2),\n",
    "                           'min_samples_leaf': uniform(loc=0, scale=0.2),\n",
    "                           'bootstrap': [True, True, False]}\n",
    "    n_splits = 5\n",
    "    n_repeats = 5\n",
    "    n_iter = 500\n",
    "    n_jobs = 90\n",
    "    verbose = 1\n",
    "    #\n",
    "    cv_xgb = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    scorer_xgb = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "    model_xgb = RandomizedSearchCV(clf_xgb, param_distributions, n_iter=n_iter,\n",
    "                                   scoring=scorer_xgb, n_jobs=n_jobs, cv=cv_xgb, verbose=verbose)\n",
    "    #\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print(\"Best model parameters: \", model_xgb.best_params_)\n",
    "    print(\"Best model roc auc score: \", model_xgb.best_score_)\n",
    "    #\n",
    "    #Mira brunch\n",
    "    clf_xgb_best=model_xgb.best_estimator_\n",
    "    clf_xgb_best.fit(X_train,y_train)\n",
    "    #\n",
    "    probs = clf_xgb_best.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    dic_res[\"best_params\"].append(model_xgb.best_params_)\n",
    "    dic_res[\"best_score\"].append(model_xgb.best_score_)\n",
    "    dic_res[\"fpr\"].append(fpr)\n",
    "    dic_res[\"tpr\"].append(tpr)\n",
    "    dic_res[\"threshold\"].append(threshold)\n",
    "    dic_res[\"auc\"].append(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer, StandardScaler, scale\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm as tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/icdm18/issues/archi_xgb_data.p\",\"rb\"))\n",
    "\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "dic_res={\"best_params\":[],\"best_score\":[],\"auc\":[],\"fpr\":[],\"tpr\":[],\"threshold\":[]}\n",
    "nb_rep_test=10\n",
    "\n",
    "for i in tqdm(range(1,nb_rep_test+1)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = RandomForestClassifier(n_estimators=1000, n_jobs=1)\n",
    "    param_distributions = {'criterion': ['gini', 'gini', 'entropy'],\n",
    "                           'max_depth': range(2,50),\n",
    "                           'min_samples_split': uniform(loc=0, scale=0.2),\n",
    "                           'min_samples_leaf': uniform(loc=0, scale=0.2),\n",
    "                           'bootstrap': [True, True, False]}\n",
    "    #\n",
    "    n_splits = 5\n",
    "    n_repeats = 10\n",
    "    n_iter = 500\n",
    "    n_jobs = -1\n",
    "    verbose = 1\n",
    "    #\n",
    "    cv_xgb = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    scorer_xgb = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "    model_xgb = RandomizedSearchCV(clf_xgb, param_distributions, n_iter=n_iter,\n",
    "                                   scoring=scorer_xgb, n_jobs=n_jobs, cv=cv_xgb, verbose=verbose)\n",
    "    #\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print(\"Best model parameters: \", model_xgb.best_params_)\n",
    "    print(\"Best model roc auc score: \", model_xgb.best_score_)\n",
    "    #\n",
    "    #Mira brunch\n",
    "    clf_xgb_best=model_xgb.best_estimator_\n",
    "    clf_xgb_best.fit(X_train,y_train)\n",
    "    #\n",
    "    probs = clf_xgb_best.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    dic_res[\"best_params\"].append(model_xgb.best_params_)\n",
    "    dic_res[\"best_score\"].append(model_xgb.best_score_)\n",
    "    dic_res[\"fpr\"].append(fpr)\n",
    "    dic_res[\"tpr\"].append(tpr)\n",
    "    dic_res[\"threshold\"].append(threshold)\n",
    "    dic_res[\"auc\"].append(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer, StandardScaler, scale\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/data_files/UKSOC_rep/uksoc_xgb_data.p\",\"rb\"))\n",
    "\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "dic_res={\"best_params\":[],\"best_score\":[],\"auc\":[],\"fpr\":[],\"tpr\":[],\"threshold\":[]}\n",
    "nb_rep_test=5\n",
    "\n",
    "for i in tqdm(range(1,nb_rep_test+1)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = XGBClassifier(silent=True, objective='binary:logistic', nthread=1,scale_pos_weight=1, base_score=0.5)\n",
    "    #\n",
    "    param_distributions = {\"max_depth\": range(3,50),\n",
    "                           \"learning_rate\": uniform(loc=0, scale=0.1),\n",
    "                           \"n_estimators\": range(10, 1500),\n",
    "                           \"min_child_weight\": range(1, 200),\n",
    "                           \"gamma\": uniform(loc=0, scale=0.1),\n",
    "                           \"subsample\": uniform(loc=0.7, scale=0.3),\n",
    "                           \"colsample_bytree\": uniform(loc=0.5, scale=0.5),\n",
    "                           \"colsample_bylevel\": uniform(loc=0.1, scale=0.9), \n",
    "                           \"reg_alpha\": uniform(loc=0, scale=0.2),\n",
    "                           \"reg_lambda\": uniform(loc=0.8, scale=0.2)}\n",
    "    #\n",
    "    n_splits = 5\n",
    "    n_repeats = 10\n",
    "    n_iter = 500\n",
    "    n_jobs = -1\n",
    "    verbose = 1\n",
    "    #\n",
    "    cv_xgb = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    scorer_xgb = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "    model_xgb = RandomizedSearchCV(clf_xgb, param_distributions, n_iter=n_iter,\n",
    "                                   scoring=scorer_xgb, n_jobs=n_jobs, cv=cv_xgb, verbose=verbose)\n",
    "    #\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print(\"Best model parameters: \", model_xgb.best_params_)\n",
    "    print(\"Best model roc auc score: \", model_xgb.best_score_)\n",
    "    #\n",
    "    #Mira brunch\n",
    "    clf_xgb_best=model_xgb.best_estimator_\n",
    "    clf_xgb_best.fit(X_train,y_train)\n",
    "    #\n",
    "    probs = clf_xgb_best.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    dic_res[\"best_params\"].append(model_xgb.best_params_)\n",
    "    dic_res[\"best_score\"].append(model_xgb.best_score_)\n",
    "    dic_res[\"fpr\"].append(fpr)\n",
    "    dic_res[\"tpr\"].append(tpr)\n",
    "    dic_res[\"threshold\"].append(threshold)\n",
    "    dic_res[\"auc\"].append(roc_auc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "dic_res[\"best_params\"].append(model_xgb.best_params_)\n",
    "dic_res[\"best_score\"].append(model_xgb.best_score_)\n",
    "dic_res[\"fpr\"].append(fpr)\n",
    "dic_res[\"tpr\"].append(tpr)\n",
    "dic_res[\"threshold\"].append(threshold)\n",
    "dic_res[\"auc\"].append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "       colsample_bylevel=0.7644347319502035,\n",
       "       colsample_bytree=0.5407410007880673, gamma=0.06575869277016731,\n",
       "       learning_rate=0.007273150630348446, max_delta_step=0, max_depth=8,\n",
       "       min_child_weight=28, missing=None, n_estimators=1272, n_jobs=10,\n",
       "       nthread=1, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0.1689331019058065, reg_lambda=0.8009806043156956,\n",
       "       scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=0.7642669507003719)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_xgb_best = XGBClassifier(silent=True,\n",
    "                             objective='binary:logistic', nthread=1,\n",
    "                             colsample_bylevel=0.7644347319502035,\n",
    "                             colsample_bytree=0.5407410007880673,\n",
    "                             gamma=0.06575869277016731,\n",
    "                             learning_rate=0.007273150630348446,\n",
    "                             max_depth=8,\n",
    "                             min_child_weight=28,\n",
    "                             n_estimators=1272,\n",
    "                             reg_alpha=0.1689331019058065,\n",
    "                             reg_lambda=0.8009806043156956,\n",
    "                             subsample=0.7642669507003719,\n",
    "                             scale_pos_weight=1, base_score=0.5,\n",
    "                            n_jobs=10)\n",
    "\n",
    "clf_xgb_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.61      0.64       752\n",
      "          1       0.63      0.68      0.66       738\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1490\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,clf_xgb_best.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer, StandardScaler, scale\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/data_files/UKSOC_rep/linkedin/linkedin_data/xgb_data.p\",\"rb\"))\n",
    "\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "dic_res={\"best_params\":[],\"best_score\":[],\"auc\":[],\"fpr\":[],\"tpr\":[],\"threshold\":[]}\n",
    "nb_rep_test=5\n",
    "\n",
    "for i in tqdmn(range(1,nb_rep_test+1)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = XGBClassifier(silent=True, objective='binary:logistic', nthread=1,scale_pos_weight=1, base_score=0.5)\n",
    "    #\n",
    "    param_distributions = {\"max_depth\": range(3,50),\n",
    "                       \"learning_rate\": uniform(loc=0, scale=0.1),\n",
    "                       \"n_estimators\": range(10, 1500),\n",
    "                       \"min_child_weight\": range(1, 200),\n",
    "                       \"gamma\": uniform(loc=0, scale=0.1),\n",
    "                       \"subsample\": uniform(loc=0.7, scale=0.3),\n",
    "                       \"colsample_bytree\": uniform(loc=0.5, scale=0.5),\n",
    "                       \"colsample_bylevel\": uniform(loc=0.1, scale=0.9),\n",
    "                       \"reg_alpha\": uniform(loc=0, scale=0.2),\n",
    "                       \"reg_lambda\": uniform(loc=0.8, scale=0.2)}\n",
    "    #\n",
    "    n_splits = 5\n",
    "    n_repeats = 10\n",
    "    n_iter = 500\n",
    "    n_jobs = -1\n",
    "    verbose = 1\n",
    "    #\n",
    "    cv_xgb = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    scorer_xgb = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "    model_xgb = RandomizedSearchCV(clf_xgb, param_distributions, n_iter=n_iter,\n",
    "                                   scoring=scorer_xgb, n_jobs=n_jobs, cv=cv_xgb, verbose=verbose)\n",
    "    #\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print(\"Best model parameters: \", model_xgb.best_params_)\n",
    "    print(\"Best model roc auc score: \", model_xgb.best_score_)\n",
    "    #\n",
    "    #Mira brunch\n",
    "    clf_xgb_best=model_xgb.best_estimator_\n",
    "    clf_xgb_best.fit(X_train,y_train)\n",
    "    #\n",
    "    probs = clf_xgb_best.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    dic_res[\"best_params\"].append(model_xgb.best_params_)\n",
    "    dic_res[\"best_score\"].append(model_xgb.best_score_)\n",
    "    dic_res[\"fpr\"].append(fpr)\n",
    "    dic_res[\"tpr\"].append(tpr)\n",
    "    dic_res[\"threshold\"].append(threshold)\n",
    "    dic_res[\"auc\"].append(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer, StandardScaler, scale\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, make_scorer, f1_score, fbeta_score, precision_score, recall_score, roc_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import uniform\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm as tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/icdm18/issues/archi_xgb_data.p\",\"rb\"))\n",
    "\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "dic_res={\"best_params\":[],\"best_score\":[],\"auc\":[],\"fpr\":[],\"tpr\":[],\"threshold\":[]}\n",
    "nb_rep_test=10\n",
    "\n",
    "for i in tqdm(range(8,nb_rep_test+1)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = XGBClassifier(silent=True, objective='binary:logistic', nthread=1,scale_pos_weight=1, base_score=0.5)\n",
    "    #\n",
    "    param_distributions = {\"max_depth\": range(3,50),\n",
    "                       \"learning_rate\": uniform(loc=0, scale=0.1),\n",
    "                       \"n_estimators\": range(10, 1500),\n",
    "                       \"min_child_weight\": range(1, 200),\n",
    "                       \"gamma\": uniform(loc=0, scale=0.1),\n",
    "                       \"subsample\": uniform(loc=0.7, scale=0.3),\n",
    "                       \"colsample_bytree\": uniform(loc=0.5, scale=0.5),\n",
    "                       \"colsample_bylevel\": uniform(loc=0.1, scale=0.9),\n",
    "                       \"reg_alpha\": uniform(loc=0, scale=0.2),\n",
    "                       \"reg_lambda\": uniform(loc=0.8, scale=0.2)}\n",
    "    #\n",
    "    n_splits = 5\n",
    "    n_repeats = 10\n",
    "    n_iter = 500\n",
    "    n_jobs = 25\n",
    "    verbose = 1\n",
    "    #\n",
    "    cv_xgb = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
    "    scorer_xgb = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)\n",
    "    model_xgb = RandomizedSearchCV(clf_xgb, param_distributions, n_iter=n_iter,\n",
    "                                   scoring=scorer_xgb, n_jobs=n_jobs, cv=cv_xgb, verbose=verbose)\n",
    "    #\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print(\"Best model parameters: \", model_xgb.best_params_)\n",
    "    print(\"Best model roc auc score: \", model_xgb.best_score_)\n",
    "    #\n",
    "    #Mira brunch\n",
    "    clf_xgb_best=model_xgb.best_estimator_\n",
    "    clf_xgb_best.fit(X_train,y_train)\n",
    "    #\n",
    "    probs = clf_xgb_best.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    dic_res[\"best_params\"].append(model_xgb.best_params_)\n",
    "    dic_res[\"best_score\"].append(model_xgb.best_score_)\n",
    "    dic_res[\"fpr\"].append(fpr)\n",
    "    dic_res[\"tpr\"].append(tpr)\n",
    "    dic_res[\"threshold\"].append(threshold)\n",
    "    dic_res[\"auc\"].append(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Average Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report2dict(cr):\n",
    "    # Parse rows\n",
    "    tmp = list()\n",
    "    for row in cr.split(\"\\n\"):\n",
    "        parsed_row = [x for x in row.split(\"  \") if len(x) > 0]\n",
    "        if len(parsed_row) > 0:\n",
    "            tmp.append(parsed_row)\n",
    "    \n",
    "    # Store in dictionary\n",
    "    measures = tmp[0]\n",
    "\n",
    "    D_class_data = defaultdict(dict)\n",
    "    for row in tmp[1:]:\n",
    "        class_label = row[0]\n",
    "        for j, m in enumerate(measures):\n",
    "            D_class_data[class_label][m.strip()] = float(row[j + 1].strip())\n",
    "    return D_class_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d7ffc4bc1441679a338dea2a15d00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "class_rep_location=[]\n",
    "import pickle\n",
    "d_test_res=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/icdm18/issues/dic_res_location_xgb.p\",\"rb\"))\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/data_files/UKSOC_rep/uksoc_xgb_data.p\",\"rb\"))\n",
    "\n",
    "nb_rep=len(d_test_res[\"auc\"])\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "for i in tqdmn(range(1,nb_rep+1)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = XGBClassifier(silent=True, objective='binary:logistic',\n",
    "                        nthread=1,scale_pos_weight=1, base_score=0.5)\n",
    "    clf_xgb.set_params(**d_test_res[\"best_params\"][i-1])\n",
    "    clf_xgb.fit(X_train,y_train)\n",
    "    class_rep_location.append(report2dict(classification_report(y_test,clf_xgb.predict(X_test))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tprecision\t0.652000\n",
      "0\trecall\t0.596000\n",
      "0\tf1-score\t0.624000\n",
      "1\tprecision\t0.628000\n",
      "1\trecall\t0.682000\n",
      "1\tf1-score\t0.652000\n"
     ]
    }
   ],
   "source": [
    "for i in [\"0\",\"1\"]:\n",
    "    for k in [\"precision\",\"recall\",\"f1-score\"]:\n",
    "        print(\"%s\\t%s\\t%3f\"%(i,k,np.mean([inst[i][k] for inst in class_rep_location])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'0': {'precision': 0.63,\n",
       "              'recall': 0.61,\n",
       "              'f1-score': 0.62,\n",
       "              'support': 731.0},\n",
       "             '1': {'precision': 0.63,\n",
       "              'recall': 0.65,\n",
       "              'f1-score': 0.64,\n",
       "              'support': 759.0},\n",
       "             'avg / total': {'precision': 0.63,\n",
       "              'recall': 0.63,\n",
       "              'f1-score': 0.63,\n",
       "              'support': 1490.0}})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_rep_location[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b01f28a05f4dcdaac5349084c953d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "class_rep_linkedin=[]\n",
    "d_test_res=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/icdm18/issues/dic_res_linkedin_xgb.p\",\"rb\"))\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/data_files/UKSOC_rep/linkedin/linkedin_data/xgb_data.p\",\"rb\"))\n",
    "\n",
    "nb_rep=len(d_test_res[\"auc\"])\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "for i in tqdmn(range(1,nb_rep+1)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = XGBClassifier(silent=True, objective='binary:logistic',\n",
    "                        nthread=1,scale_pos_weight=1, base_score=0.5)\n",
    "    clf_xgb.set_params(**d_test_res[\"best_params\"][i-1])\n",
    "    clf_xgb.fit(X_train,y_train)\n",
    "    class_rep_linkedin.append(report2dict(classification_report(y_test,clf_xgb.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tprecision\t0.700000\n",
      "0\trecall\t0.732500\n",
      "0\tf1-score\t0.717500\n",
      "1\tprecision\t0.735000\n",
      "1\trecall\t0.702500\n",
      "1\tf1-score\t0.720000\n"
     ]
    }
   ],
   "source": [
    "for i in [\"0\",\"1\"]:\n",
    "    for k in [\"precision\",\"recall\",\"f1-score\"]:\n",
    "        print(\"%s\\t%s\\t%3f\"%(i,k,np.mean([inst[i][k] for inst in class_rep_linkedin])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46eb053c052141c29cf4842acf1b336d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlevyabi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "class_rep_archi=[]\n",
    "d_test_res=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/icdm18/issues/dic_res_archi_xgb.p\",\"rb\"))\n",
    "d_test_brunch=pickle.load(open(\"/warehouse/COMPLEXNET/jlevyabi/TWITTERSES/ml_soc_econ/icdm18/issues/archi_xgb_data.p\",\"rb\"))\n",
    "\n",
    "nb_rep=len(d_test_res[\"auc\"])\n",
    "X_train=d_test_brunch[\"Xtrain\"]\n",
    "X_test=d_test_brunch[\"Xtest\"]\n",
    "y_train=d_test_brunch[\"Ytrain\"]\n",
    "y_test=d_test_brunch[\"Ytest\"]\n",
    "\n",
    "X=np.vstack([X_train,X_test])\n",
    "y=np.hstack([y_train,y_test])\n",
    "\n",
    "for i in tqdmn(range(1,nb_rep+1)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state=i)\n",
    "    clf_xgb = XGBClassifier(silent=True, objective='binary:logistic',\n",
    "                        nthread=1,scale_pos_weight=1, base_score=0.5)\n",
    "    clf_xgb.set_params(**d_test_res[\"best_params\"][i-1])\n",
    "    clf_xgb.fit(X_train,y_train)\n",
    "    class_rep_archi.append(report2dict(classification_report(y_test,clf_xgb.predict(X_test))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tprecision\t0.621667\n",
      "0\trecall\t0.598333\n",
      "0\tf1-score\t0.606667\n",
      "1\tprecision\t0.550000\n",
      "1\trecall\t0.573333\n",
      "1\tf1-score\t0.556667\n"
     ]
    }
   ],
   "source": [
    "for i in [\"0\",\"1\"]:\n",
    "    for k in [\"precision\",\"recall\",\"f1-score\"]:\n",
    "        print(\"%s\\t%s\\t%3f\"%(i,k,np.mean([inst[i][k] for it,inst in enumerate(class_rep_archi) if not(it in[0,1,3,5])])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'0': {'precision': 0.64,\n",
       "              'recall': 0.65,\n",
       "              'f1-score': 0.65,\n",
       "              'support': 49.0},\n",
       "             '1': {'precision': 0.56,\n",
       "              'recall': 0.55,\n",
       "              'f1-score': 0.56,\n",
       "              'support': 40.0},\n",
       "             'avg / total': {'precision': 0.61,\n",
       "              'recall': 0.61,\n",
       "              'f1-score': 0.61,\n",
       "              'support': 89.0}})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_rep_archi[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
